# PyTorch Object Detection

This project is a PyTorch-based object detection pipeline for classifying drink fullness levels (e.g., `full`, `not_full`, `foam_ready`). It is based on and adapted from the excellent open-source repository:  
ğŸ‘‰ [qfgaohao/pytorch-ssd](https://github.com/qfgaohao/pytorch-ssd)

We customized the data pipeline, training logic, and inference scripts for practical deployment on desktop GPUs and NVIDIA Jetson devices.

---

## ğŸ“¦ Environment Setup

```bash
python -m venv venv
source venv/bin/activate       # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸ“ Directory Overview

```
PyTorch Object Detection/
â”œâ”€â”€ core/                    # Core logic: training, preprocessing, augmentation
â”‚   â”œâ”€â”€ train_ssd_cleaned.py
â”‚   â”œâ”€â”€ voc_dataset.py
â”‚   â”œâ”€â”€ transforms.py
â”‚   â”œâ”€â”€ predictor.py
â”‚   â””â”€â”€ data_preprocessing.py
â”‚
â”œâ”€â”€ scripts/                 # Inference & export tools
â”‚   â”œâ”€â”€ pth_image.py
â”‚   â”œâ”€â”€ pth_video.py
â”‚   â”œâ”€â”€ onnx_image.py
â”‚   â”œâ”€â”€ onnx_video.py
â”‚   â””â”€â”€ export_onnx.py
â”‚
â”œâ”€â”€ sample_transfer/         # Sample input/output videos
â”‚   â”œâ”€â”€ Aloha_breeze.mp4
â”‚   â”œâ”€â”€ Aloha_breeze_pth_output.mp4
â”‚   â””â”€â”€ Aloha_breeze_onnx_output.mp4
â”‚
â”œâ”€â”€ mb2-ssd-lite-mp-0_686.pth  # Pretrained MobileNetV2-SSD model
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§  Workflow

1. **Prepare Pretrained Model**  
   Download and place `mb2-ssd-lite-mp-0_686.pth` in the project root.

2. **Dataset Preparation (VOC Format)**  
   Use [CVAT](https://github.com/opencv/cvat) to annotate and export video frames.  
   Format should match Pascal VOC (XML + JPEG + ImageSets).

3. **Train the Model**

```bash
python core/train_ssd_cleaned.py ^
  --dataset_type voc ^
  --datasets VOC2007 ^
  --net mb2-ssd-lite ^
  --pretrained_ssd mb2-ssd-lite-mp-0_686.pth ^
  --batch_size 64 ^
  --num_epochs 100 ^
  --scheduler cosine ^
  --num_workers 24
```

4. **Run Inference with PyTorch Model**

```bash
python scripts/pth_image.py    # Inference on images
python scripts/pth_video.py    # Inference on videos
```

5. **Export to ONNX Format**

```bash
python scripts/export_onnx.py
```

6. **Run Inference with ONNX Model**

```bash
python scripts/onnx_image.py   # ONNX inference on images
python scripts/onnx_video.py   # ONNX inference on videos
```

> ONNX models are optimized for deployment on NVIDIA Jetson platforms, especially with [TensorRT](https://developer.nvidia.com/tensorrt) or `detectnet` pipelines.

---

## ğŸ¤ Acknowledgements

- [qfgaohao/pytorch-ssd](https://github.com/qfgaohao/pytorch-ssd) â€” base architecture
- [NVIDIA Jetson](https://developer.nvidia.com/embedded-computing) â€” edge deployment

---

## ğŸ“Œ Author

Xiaotian Lin